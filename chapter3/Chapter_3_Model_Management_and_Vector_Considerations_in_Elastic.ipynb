{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uA0d_STPW7za"
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ud4E6TlXFXP"
   },
   "source": [
    "# IMDB 데이터 세트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpXxbN_bXBfo"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "imdb_dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCFJODgdXW33"
   },
   "source": [
    "# imdb 데이터 세트 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFW5jLzJXe6d"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# IMDB 데이터 세트 일부(샘플 100개) 적재\n",
    "imdb_dataset = load_dataset(\"imdb\", split=\"train[:100]\")\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 자르기와 패딩을 사용해 IMDB 데이터 세트 토큰화\n",
    "tokenized_imdb_dataset = imdb_dataset.map(\n",
    "lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\")\n",
    ")\n",
    "\n",
    "print(tokenized_imdb_dataset)\n",
    "\n",
    "# 토큰의 첫 번째 행 가져오기\n",
    "first_row_tokens = tokenized_imdb_dataset[0][\"input_ids\"]\n",
    "\n",
    "# 처음 10개 토큰과 토큰에 해당하는 단어 출력\n",
    "for token in first_row_tokens[:10]:\n",
    "  print(f\"토큰: {token}, 단어: {tokenizer.decode([token])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sEIuAX1Y12I"
   },
   "source": [
    "# Spaces 예제 코드\n",
    "Gradio 인터페이스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b9qSiukY9kK"
   },
   "outputs": [],
   "source": [
    "!pip install gradio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEvaRRUpY5tB"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    result = sentiment_pipeline(text)\n",
    "    return result[0][\"label\"]\n",
    "\n",
    "iface = gr.Interface(fn=sentiment_analysis, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1821xMLhZRGw"
   },
   "source": [
    "# 일래스틱 Eland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeHEK6A-ZbA7"
   },
   "outputs": [],
   "source": [
    "!pip install eland elasticsearch seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB_055jlaH2H"
   },
   "source": [
    "# 인덱스 생성 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLkd_1KWo6ba"
   },
   "source": [
    "## 일래스틱서치에 접속하여 샘플 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vnErFw4o8eh"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "\n",
    "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "es_api_key = getpass.getpass('Enter cluster API key:  ')\n",
    "\n",
    "es = Elasticsearch(cloud_id=es_cloud_id,\n",
    "                   api_key=es_api_key\n",
    "                   )\n",
    "es.info() # 클러스터 정보가 반환돼야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"some_field\": {\"type\": \"float\"},\n",
    "            \"column_a\": {\"type\": \"float\"},\n",
    "            \"column_b\": {\"type\": \"float\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"value\": {\"type\": \"float\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 인덱스 생성\n",
    "es.indices.create(index=\"sample_eland_index\", body=mapping)\n",
    "\n",
    "# 인덱스에 샘플 데이터 넣기\n",
    "documents = [\n",
    "    {\"some_field\": 95.0, \"column_a\": 5.0, \"column_b\": 10.0, \"category\": \"A\", \"value\": 50.0},\n",
    "    {\"some_field\": 150.0, \"column_a\": 7.0, \"column_b\": 20.0, \"category\": \"B\", \"value\": 140.0},\n",
    "    {\"some_field\": 200.0, \"column_a\": 8.0, \"column_b\": 25.0, \"category\": \"A\", \"value\": 200.0},\n",
    "    {\"some_field\": 50.0, \"column_a\": 4.0, \"column_b\": 12.5, \"category\": \"C\", \"value\": 50.0}\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    es.index(index=\"sample_eland_index\", body=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJzKKd6opNLf"
   },
   "source": [
    "## Eland 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puzcRKXHZTeB"
   },
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "\n",
    "df = ed.DataFrame(es_client=es, es_index_pattern=\"sample_eland_index\")\n",
    "filtered_df = df[df['some_field'] > 100]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kchuV7LmZ94y"
   },
   "outputs": [],
   "source": [
    "average_value = df['some_field'].mean()\n",
    "average_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUt_BZrQaA1l"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "filtered_df = df[df['some_field'] > 100]\n",
    "pandas_df = filtered_df.to_pandas()\n",
    "sns.boxplot(x='category', y='value', data=pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LyU11jZaK_s"
   },
   "source": [
    "# 허깅 페이스의 모델을 일래스틱서치에서 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERArF6WFaNt6"
   },
   "outputs": [],
   "source": [
    "pip -q install eland elasticsearch transformers sentence_transformers torch==1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD-ajPzoaiCf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CboLpvAatQv"
   },
   "outputs": [],
   "source": [
    "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "es_api_key = getpass.getpass('Enter cluster API key:  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlNW7YKJau7O"
   },
   "outputs": [],
   "source": [
    "# 일래스틱 클라우드 연결\n",
    "es = Elasticsearch(cloud_id=es_cloud_id,\n",
    "                   api_key=es_api_key\n",
    "                   )\n",
    "es.info() # 클러스터 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSyXy5aJa10s"
   },
   "outputs": [],
   "source": [
    "hf_model_id='sentence-transformers/msmarco-MiniLM-L-12-v3'\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4MsWWhga4CX"
   },
   "outputs": [],
   "source": [
    "es_model_id = tm.elasticsearch_model_id()\n",
    "es_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKtX28bTa50r"
   },
   "outputs": [],
   "source": [
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nI3Ppm9ea7vW"
   },
   "outputs": [],
   "source": [
    "ptm = PyTorchModel(es, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvRE1GPwa9aZ"
   },
   "outputs": [],
   "source": [
    "# 일래스틱서치에 존재하는 모델 정보 조회\n",
    "m = MlClient.get_trained_models(es, model_id=es_model_id)\n",
    "m.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L1rccH1a-zu"
   },
   "outputs": [],
   "source": [
    "s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BQB368zbAyT"
   },
   "outputs": [],
   "source": [
    "stats = MlClient.get_trained_models_stats(es, model_id=es_model_id)\n",
    "stats.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZELyEJvUbLOW"
   },
   "outputs": [],
   "source": [
    "docs =  [\n",
    "    {\n",
    "      \"text_field\": \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZ8U1oHGbM4l"
   },
   "outputs": [],
   "source": [
    "z = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5q3j1WDmbNRT"
   },
   "outputs": [],
   "source": [
    "doc_0_vector = z['inference_results'][0]['predicted_value']\n",
    "doc_0_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJT9EOxmn6pZ"
   },
   "source": [
    "# 차원 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh5QvWj-n9Ri"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyYMdCXNoChF"
   },
   "outputs": [],
   "source": [
    "# Iris 데이터 세트 적재\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 차원 축소를 위해 PCA 적용\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgQwUpBJoFIg"
   },
   "outputs": [],
   "source": [
    "# 원 데이터 시각화\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Original Iris dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2x7VthJoIMu"
   },
   "outputs": [],
   "source": [
    "# 차원 축소된 데이터 시각화\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('Iris dataset after PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUluTeh2oXYX"
   },
   "source": [
    "# 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPY1tGMvoY7L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zUhu904oede"
   },
   "outputs": [],
   "source": [
    "# 숫자 데이터 세트 불러오기\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "\n",
    "# 원본 데이터 세트에서 첫 번째 예시 출력\n",
    "print(\"Original dataset (first example):\\n\", X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWSyzBeqoltn"
   },
   "outputs": [],
   "source": [
    "# 차원 축소를 위해 PCA 적용\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# PCA 적용 후 첫 번째 예시 출력\n",
    "print(\"\\nReduced dataset after PCA (first example):\\n\", X_reduced[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcNn_VWqon0t"
   },
   "outputs": [],
   "source": [
    "# 축소된 벡터를 [0, 255] 범위로 정규화\n",
    "scaler = MinMaxScaler((0, 255))\n",
    "X_scaled = scaler.fit_transform(X_reduced)\n",
    "\n",
    "# 정규화 후 첫 번째 예시 출력\n",
    "print(\"\\nScaled dataset after normalization (first example):\\n\", X_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-R0I53hoqNj"
   },
   "outputs": [],
   "source": [
    "# 스케일링 된 벡터를 8비트 정수로 양자화\n",
    "X_quantized = np.round(X_scaled).astype(np.uint8)\n",
    "\n",
    "# 양자화 후 첫 번째 예시 출력\n",
    "print(\"\\nQuantized dataset (first example):\\n\", X_quantized[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
