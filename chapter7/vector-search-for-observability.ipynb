{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faker\n",
    "!pip install openai\n",
    "!pip install elasticsearch\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 합성 로그 생성 함수"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# 1. 아파치 HTTP 서버 (일반 로그 형식)\n",
    "def generate_apache_log():\n",
    "    return '{RemoteHost} - - [{Timestamp}] \"{RequestMethod} {RequestURI} {Protocol}\" {StatusCode} {ResponseSize}'.format(\n",
    "        RemoteHost=fake.ipv4(),\n",
    "        Timestamp=fake.date_time_this_year().strftime('%d/%b/%Y:%H:%M:%S %z'),\n",
    "        RequestMethod=fake.http_method(),\n",
    "        RequestURI=fake.uri(),\n",
    "        Protocol='HTTP/1.1',\n",
    "        StatusCode=random.choice([200, 404, 500]),\n",
    "        ResponseSize=random.randint(100, 10000)\n",
    "    )\n",
    "\n",
    "# 2. 엔진엑스 (혼합 로그 형식)\n",
    "def generate_nginx_log():\n",
    "    return '{RemoteAddress} - {RemoteUser} [{Timestamp}] \"{RequestMethod} {RequestURI} {Protocol}\" {StatusCode} {ResponseSize} \\\n",
    "\"{Referer}\" \"{UserAgent}\"'.format(\n",
    "        RemoteAddress=fake.ipv4(),\n",
    "        RemoteUser='-',\n",
    "        Timestamp=fake.date_time_this_year().strftime('%d/%b/%Y:%H:%M:%S %z'),\n",
    "        RequestMethod=fake.http_method(),\n",
    "        RequestURI=fake.uri(),\n",
    "        Protocol='HTTP/1.1',\n",
    "        StatusCode=random.choice([200, 404, 500]),\n",
    "        ResponseSize=random.randint(100, 10000),\n",
    "        Referer=fake.uri(),\n",
    "        UserAgent=fake.user_agent()\n",
    "    )\n",
    "\n",
    "# 3. 시스로그 (RFC 5424)\n",
    "def generate_syslog():\n",
    "    return '<{Priority}>{Version} {Timestamp} {Hostname} {AppName} {ProcID} {MsgID} {StructuredData} {Message}'.format(\n",
    "        Priority=random.randint(1, 191),\n",
    "        Version=1,\n",
    "        Timestamp=fake.date_time_this_year().isoformat(),\n",
    "        Hostname=fake.hostname(),\n",
    "        AppName=fake.word(),\n",
    "        ProcID=random.randint(1000, 9999),\n",
    "        MsgID=random.randint(1000, 9999),\n",
    "        StructuredData='-',\n",
    "        Message=fake.sentence()\n",
    "    )\n",
    "\n",
    "# 4. 아마존 웹 서비스 클라우드 트레일\n",
    "def generate_aws_cloudtrail_log():\n",
    "    return '{{\"eventVersion\": \"{EventVersion}\", \"userIdentity\": {{\"type\": \"IAMUser\", \"userName\": \"{UserName}\"}}, \\\n",
    "\"eventTime\": \"{Timestamp}\", \"eventSource\": \"{EventSource}\", \"eventName\": \"{EventName}\", \"awsRegion\": \"{AwsRegion}\" , \\\n",
    "\"sourceIPAddress\": \"{SourceIPAddress}\", \"userAgent\": \"{UserAgent}\", \"requestParameters\": {{\"key\": \"value\"}}, \\\n",
    "\"responseElements\": {{\"key\": \"value\"}}, \"requestID\": \"{RequestId}\", \"eventID\": \"{EventId}\", \"eventType\": \"AwsApiCall\", \\\n",
    "\"recipientAccountId\": \"{RecipientAccountId}\"}}'.format(\n",
    "        EventVersion='1.08',\n",
    "        UserName=fake.user_name(),\n",
    "        Timestamp=fake.date_time_this_year().isoformat(),\n",
    "        EventSource='s3.amazonaws.com',\n",
    "        EventName='GetObject',\n",
    "        AwsRegion='us-east-1',\n",
    "        SourceIPAddress=fake.ipv4(),\n",
    "        UserAgent=fake.user_agent(),\n",
    "        RequestId=fake.uuid4(),\n",
    "        EventId=fake.uuid4(),\n",
    "        RecipientAccountId=fake.random_number(digits=12)\n",
    "    )\n",
    "\n",
    "# 5. 마이크로소프트 윈도우즈 이벤트 로그\n",
    "def generate_windows_event_log():\n",
    "    return '<Event xmlns=\"http://schemas.microsoft.com/win/2004/08/events/event\"><System><Provider Name=\"{ProviderName}\"/>\\\n",
    "<EventID>{EventID}</EventID><Level>{Level}</Level><TimeCreated SystemTime=\"{Timestamp}\"/><SourceName>{SourceName}</SourceName>\\\n",
    "<Computer>{Computer}</Computer></System><EventData>{Message}</EventData></Event>'.format(\n",
    "        ProviderName=fake.word(),\n",
    "        EventID=random.randint(1000, 9999),\n",
    "        Level=random.randint(1, 5),\n",
    "        Timestamp=fake.date_time_this_year().isoformat(),\n",
    "        SourceName=fake.word(),\n",
    "        Computer=fake.hostname(),\n",
    "        Message=fake.sentence()\n",
    "    )\n",
    "\n",
    "# 6. 리눅스 감사 로그\n",
    "def generate_linux_audit_log():\n",
    "    return 'type={AuditType} msg=audit({Timestamp}): {Message}'.format(\n",
    "        AuditType=fake.word(),\n",
    "        Timestamp=fake.date_time_this_year().isoformat(),\n",
    "        Message=fake.sentence()\n",
    "    )\n",
    "\n",
    "def generate_logs(sources, total_logs, random_logs):\n",
    "    # 함수 이름과 로그 종류 맵핑\n",
    "    source_to_function = {\n",
    "        'apache': generate_apache_log,\n",
    "        'nginx': generate_nginx_log,\n",
    "        'syslog': generate_syslog,\n",
    "        'aws_cloudtrail': generate_aws_cloudtrail_log,\n",
    "        'windows_event': generate_windows_event_log,\n",
    "        'linux_audit': generate_linux_audit_log,\n",
    "    }\n",
    "    \n",
    "    # 각 로그 종류별로 생성할 로그의 수 계산\n",
    "    num_sources = len(sources)\n",
    "    logs_per_source = [total_logs // num_sources] * num_sources\n",
    "    if random_logs:\n",
    "        for i in range(total_logs % num_sources):\n",
    "            logs_per_source[i] += 1\n",
    "        random.shuffle(logs_per_source)\n",
    "    \n",
    "    # 로그를 생성하고 리스트에 생성된 합성 로그 추가\n",
    "    generated_logs = []\n",
    "    for source, num_logs in zip(sources, logs_per_source):\n",
    "        log_function = source_to_function[source]\n",
    "        for _ in range(num_logs):\n",
    "            generated_logs.append(log_function())\n",
    "    \n",
    "    return generated_logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## OpenAI를 활용한 로그 확장"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 활용 예\n",
    "sources_to_use = ['apache']\n",
    "total_logs_to_generate = 15\n",
    "random_logs_per_source = True\n",
    "logs = generate_logs(sources_to_use, total_logs_to_generate, random_logs_per_source)\n",
    "\n",
    "\n",
    "stringifiedPromptsArray = json.dumps(logs)\n",
    "\n",
    "print(\"Logs: \")\n",
    "print(logs)\n",
    "\n",
    "prompts = [\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": stringifiedPromptsArray\n",
    "    }\n",
    "]\n",
    "\n",
    "batchInstruction = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"Explain what happened for each log line of the array. Return a python array of the explanation. Only the array, no text around it or any extra comment, nothing else than the array should be in the answer. Don't forget in your completion to give the day, date and year of the log. Interpret some of the log content if you can, for example you have to translate what an error code 500.\"\n",
    "}\n",
    "\n",
    "prompts.append(batchInstruction)\n",
    "print(\"ChatGPT: \")\n",
    "\n",
    "\n",
    "# OpenAI API 키 선언\n",
    "openai_api_key = \"OPENAI_API_KEY\"\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "stringifiedBatchCompletion = openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=prompts, max_tokens=1000)\n",
    "print(stringifiedBatchCompletion.choices[0].message.content)\n",
    "batchCompletion = ast.literal_eval(stringifiedBatchCompletion.choices[0].message.content)\n",
    "\n",
    "#batchCompletion"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로그 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일래스틱서치 접속 정보 입력\n",
    "import getpass\n",
    "es_cloud_id = getpass.getpass('Enter Elastic Cloud ID: ') \n",
    "es_api_id = getpass.getpass('Enter cluster API key ID: ') \n",
    "es_api_key = getpass.getpass('Enter cluster API key: ')\n",
    "\n",
    "# 일래스틱 클라우드 접속\n",
    "es = Elasticsearch(cloud_id=es_cloud_id, api_key=(es_api_id, es_api_key))\n",
    "\n",
    "# 인덱스 맵핑 설정\n",
    "index_config = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"description_vectorized\": {\n",
    "        \"type\": \"dense_vector\",\n",
    "        \"dims\": 768,\n",
    "        \"index\": True,\n",
    "        \"similarity\": \"cosine\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# 인덱스 생성\n",
    "response = es.indices.create(index='logs', body=index_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### ※ 일괄 색인 수행 전 7.4.2 모델 저장, 7.4.3 수집 파이프라인 생성 단계 수행이 필요합니다. "
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 일괄 색인을 위한 JSON 문서 생성 \n",
    "bulk_index_body = []\n",
    "for index, log in enumerate(batchCompletion):\n",
    "    document = {\n",
    "        \"_index\": \"logs\", \n",
    "        \"pipeline\": \"vectorize-log\",\n",
    "        \"_source\": {\n",
    "            \"text_field\": log, \"log\": logs[index]\n",
    "        }\n",
    "    }\n",
    "    bulk_index_body.append(document)\n",
    "\n",
    "# 일괄 색인 문서 확인 \n",
    "print(\"Bulk request: \")\n",
    "print(bulk_index_body)\n",
    "\n",
    "try:\n",
    "    response = helpers.bulk(es, bulk_index_body)\n",
    "    print (\"\\nRESPONSE:\", response)\n",
    "except Exception as e:\n",
    "    print(\"\\nERROR:\", e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시맨틱 검색"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def ESSearch(query_text):\n",
    "  # 일래스틱서치 BM25와 kNN 하이브리드 검색\n",
    "  query = {\n",
    "    \"bool\": {\n",
    "      \"filter\": [{\n",
    "        \"exists\": {\n",
    "          \"field\": \"description_vectorized\"\n",
    "        }\n",
    "      }]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  knn = {\n",
    "    \"field\": \"description_vectorized\",\n",
    "    \"k\": 1,\n",
    "    \"num_candidates\": 20,\n",
    "    \"query_vector_builder\": {\n",
    "      \"text_embedding\": {\n",
    "        \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "        \"model_text\": query_text\n",
    "      }\n",
    "    },\n",
    "    \"boost\": 24\n",
    "  }\n",
    "\n",
    "  fields = [\"text_field\"]\n",
    "  index = 'logs'\n",
    "  resp = es.search(index=index,\n",
    "                   query=query,\n",
    "                   knn=knn,\n",
    "                   fields=fields,\n",
    "                   size=1,\n",
    "                   source=False)\n",
    "\n",
    "\n",
    "  #print(resp['hits']['hits'][0]['fields']['text_field'][0])\n",
    "  return resp['hits']['hits'][0]['fields']['text_field'][0]\n",
    "\n",
    "\n",
    "ESSearch(\"Were there any error in March?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4.2 모델 저장 - 일래스틱서치에 임베딩 모델 로드하기\n",
    "#### 임베딩에 필요한 모델을 일래스틱서치에 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요시 관련 라이브러리 설치  \n",
    "from pathlib import Path\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "\n",
    "# 허깅 페이스의 모델명과 작업 유형 설정\n",
    "hf_model_id='sentence-transformers/all-distilroberta-v1'\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_embedding\")\n",
    "\n",
    "# 일래스틱서치에서 이름으로 사용할 modelID 설정\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# 허깅 페이스에서 모델 다운로드\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# 일래스틱서치에 모델 저장\n",
    "ptm = PyTorchModel(es, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.client import MlClient\n",
    "\n",
    "# 모델을 사용할 수 있는 상태로 배포\n",
    "s = MlClient.start_trained_model_deployment(es, model_id=es_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 임베딩 모델 정상 동작 여부 확인 \n",
    "docs = [\n",
    "    {\n",
    "        \"text_field\": \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "z = MlClient.infer_trained_model(es, model_id=es_model_id, docs=docs)\n",
    "doc_0_vector = z['inference_results'][0]['predicted_value']\n",
    "doc_0_vector"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4.3 수집 파이프라인 생성\n",
    "#### 아래의 일래스틱서치 API를 키바나에서 수행하여 일괄 색인 API에서 활용되는 vectorize-log 파이프라인을 정의합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PUT _ingest/pipeline/vectorize-log\n",
    "#{\n",
    "#  \"description\": \"ingest pipe for chapter 7\",\n",
    "#    \"processors\": [\n",
    "#    {\n",
    "#      \"inference\": {\n",
    "#        \"model_id\": \"sentence-transformers__all-distilroberta-v1\",\n",
    "#        \"target_field\": \"description_vectorized\"\n",
    "#      }\n",
    "#    },\n",
    "#    {\n",
    "#      \"set\": {\n",
    "#        \"field\": \"description_vectorized\",\n",
    "#        \"copy_from\": \"description_vectorized.predicted_value\"\n",
    "#      }\n",
    "#    }\n",
    "#  ]\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
